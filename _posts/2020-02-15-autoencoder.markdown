---
layout: post
title: Autoencoder
date: 2019-12-20 9:12:20 -0500
description: Youâ€™ll find this post in your `_posts` directory. Go ahead and edit it and re-build the site to see your changes. # Add post description (optional)
img: /post/demo_autoencoder.png # Add image post (optional)
fig-caption: # Add figcaption (optional)
tags: [Autoencoder]
---

The autoencoder is a neural networks that is trained to try to copy its input to its output. It is composed of two parts: an encoder that is trained to generate a code <b>h</b> that describe the input <b>x</b>. The encondes can be represented by the function <b>f</b>, then the code generate by the encoder is <b>h = f(x)</b>. The second part is a decoder thet produces a reconstruction from the code <b>h</b> generated by encoder. It can be represented by the function $g$ and its ouput is <b>x' = g(h)</b> or <b>x' = g(f(x))</b>. The architecture is shown in next Figure:

![Autoencoder]({{site.baseurl}}/assets/img/post/autoencoder.png)

In the process of training an autoencoder, it is prioritized that the model learns to which aspect of the input should be copied. In other words, the autoencoder tries to learn an approximation to the identity function where the output <b>x'</b> is similar to the input <b>x</b>. 
The autoencoder is an interesting network because it has a hidden layer that the output is the code <b>h</b>. If the size of <b>h</b> code is less than the size of the input <b>x</b>, the model is forced to learn the useful properties of the data. Then, <b>h</b> contains the appropriate information to the decoder reproduces an output <b>x'</b> similar to the input <b>x</b>. Therefore, the autoencoder can compress the input data in a <b>h</b> code that is a latent-space representation.

The autoencoder is tipically  used for:
<ul>
  <li>Dimensionality reduction</li>
  <li>Denoising</li>
  <li>Anomaly detection</li>
</ul>
